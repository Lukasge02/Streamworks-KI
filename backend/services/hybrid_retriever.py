"""
Hybrid Retriever - State-of-the-Art Dense + Sparse Retrieval
Combines vector-based semantic search with BM25 keyword search
"""

import asyncio
import logging
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

from .vectorstore import VectorStoreService
from .embeddings import EmbeddingService
from .bm25_service import BM25Service, BM25SearchResult
from config import settings

logger = logging.getLogger(__name__)

class RetrievalStrategy(Enum):
    """Retrieval strategy selection"""
    SEMANTIC = "semantic"      # Pure vector search
    KEYWORD = "keyword"        # Pure BM25 search  
    HYBRID = "hybrid"          # Combined approach
    ADAPTIVE = "adaptive"      # Query-dependent selection

@dataclass
class HybridSearchResult:
    """Unified search result from hybrid retrieval"""
    chunk_id: str
    doc_id: str
    content: str
    metadata: Dict[str, Any]
    
    # Scoring details
    final_score: float
    dense_score: float
    sparse_score: float
    
    # Fusion details
    dense_rank: Optional[int] = None
    sparse_rank: Optional[int] = None
    fusion_weight: float = 0.5
    
    # Source information
    matched_terms: Optional[List[str]] = None
    retrieval_source: str = "hybrid"

class HybridRetriever:
    """
    Advanced Hybrid Retrieval System
    
    Features:
    - Intelligent query classification for optimal strategy selection
    - Reciprocal Rank Fusion (RRF) for result combination
    - Adaptive weight adjustment based on query characteristics
    - Performance monitoring and auto-tuning
    """
    
    def __init__(self, 
                 vectorstore: VectorStoreService,
                 embeddings: EmbeddingService,
                 bm25: Optional[BM25Service] = None,
                 dense_weight: float = 0.6,
                 sparse_weight: float = 0.4):
        """
        Initialize Hybrid Retriever
        
        Args:
            vectorstore: Vector database service
            embeddings: Embedding service
            bm25: BM25 service (will create if None)
            dense_weight: Weight for vector search results (0.0-1.0)
            sparse_weight: Weight for BM25 results (0.0-1.0)
        """
        self.vectorstore = vectorstore
        self.embeddings = embeddings
        self.bm25 = bm25 or BM25Service()
        
        # Fusion weights (should sum to 1.0)
        self.dense_weight = dense_weight
        self.sparse_weight = sparse_weight
        self._normalize_weights()
        
        # Performance tracking
        self.query_stats = {\n            'total_queries': 0,\n            'semantic_queries': 0,\n            'keyword_queries': 0,\n            'hybrid_queries': 0,\n            'avg_response_time': 0.0\n        }\n        \n        # Query classification patterns\n        self.keyword_indicators = {\n            'exact_quotes': r'\"[^\"]+\"',\n            'technical_terms': r'\\b(?:API|HTTP|SSL|TLS|JSON|XML|SQL|v\\d+\\.\\d+)\\b',\n            'numbers': r'\\b\\d+(?:\\.\\d+)?\\b',\n            'codes': r'\\b[A-Z]+-\\d+\\b',\n            'boolean_ops': r'\\b(?:AND|OR|NOT)\\b'\n        }\n        \n        logger.info(f\"ðŸ”„ HybridRetriever initialized - dense: {dense_weight:.1f}, sparse: {sparse_weight:.1f}\")\n    \n    def _normalize_weights(self):\n        \"\"\"Ensure weights sum to 1.0\"\"\"\n        total = self.dense_weight + self.sparse_weight\n        if total > 0:\n            self.dense_weight /= total\n            self.sparse_weight /= total\n        else:\n            self.dense_weight = 0.6\n            self.sparse_weight = 0.4\n    \n    async def initialize(self):\n        \"\"\"Initialize all retrieval services\"\"\"\n        try:\n            # Initialize vector store\n            if not hasattr(self.vectorstore, 'collection') or not self.vectorstore.collection:\n                await self.vectorstore.initialize()\n            \n            # Initialize embeddings\n            await self.embeddings.initialize()\n            \n            # Load BM25 index if available\n            await self.bm25.load_index()\n            \n            logger.info(\"âœ… HybridRetriever initialized successfully\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to initialize HybridRetriever: {str(e)}\")\n            raise\n    \n    async def search(\n        self,\n        query: str,\n        top_k: int = 10,\n        strategy: RetrievalStrategy = RetrievalStrategy.ADAPTIVE,\n        filters: Optional[Dict[str, Any]] = None,\n        dense_top_k: Optional[int] = None,\n        sparse_top_k: Optional[int] = None\n    ) -> List[HybridSearchResult]:\n        \"\"\"\n        Perform hybrid search combining dense and sparse retrieval\n        \n        Args:\n            query: Search query\n            top_k: Number of final results\n            strategy: Retrieval strategy\n            filters: Optional metadata filters\n            dense_top_k: Override top_k for vector search\n            sparse_top_k: Override top_k for BM25 search\n            \n        Returns:\n            List of HybridSearchResult objects\n        \"\"\"\n        start_time = time.time()\n        self.query_stats['total_queries'] += 1\n        \n        try:\n            # Determine optimal strategy\n            if strategy == RetrievalStrategy.ADAPTIVE:\n                strategy = self._classify_query(query)\n            \n            # Set retrieval parameters\n            if dense_top_k is None:\n                dense_top_k = min(top_k * 2, 20)  # Get more candidates for fusion\n            if sparse_top_k is None:\n                sparse_top_k = min(top_k * 2, 20)\n            \n            logger.debug(f\"Hybrid search: '{query}' using {strategy.value} strategy\")\n            \n            # Execute retrieval based on strategy\n            if strategy == RetrievalStrategy.SEMANTIC:\n                results = await self._semantic_only_search(query, top_k, filters)\n                self.query_stats['semantic_queries'] += 1\n                \n            elif strategy == RetrievalStrategy.KEYWORD:\n                results = await self._keyword_only_search(query, top_k, filters)\n                self.query_stats['keyword_queries'] += 1\n                \n            else:  # HYBRID\n                results = await self._hybrid_fusion_search(\n                    query, top_k, filters, dense_top_k, sparse_top_k\n                )\n                self.query_stats['hybrid_queries'] += 1\n            \n            # Update performance stats\n            response_time = time.time() - start_time\n            self._update_performance_stats(response_time)\n            \n            logger.info(f\"Hybrid search completed: {len(results)} results in {response_time:.3f}s\")\n            return results\n            \n        except Exception as e:\n            logger.error(f\"Hybrid search failed: {str(e)}\")\n            return []\n    \n    def _classify_query(self, query: str) -> RetrievalStrategy:\n        \"\"\"\n        Classify query to determine optimal retrieval strategy\n        \n        Returns:\n            Best retrieval strategy for the query\n        \"\"\"\n        import re\n        \n        keyword_score = 0\n        semantic_score = 0\n        \n        query_lower = query.lower()\n        \n        # Check for keyword indicators\n        for pattern_name, pattern in self.keyword_indicators.items():\n            if re.search(pattern, query, re.IGNORECASE):\n                keyword_score += 1\n                logger.debug(f\"Query matches {pattern_name} pattern\")\n        \n        # Check query characteristics\n        word_count = len(query.split())\n        \n        # Short queries with specific terms â†’ keyword search\n        if word_count <= 3 and keyword_score > 0:\n            return RetrievalStrategy.KEYWORD\n        \n        # Questions and natural language â†’ semantic search\n        if any(q in query_lower for q in ['wie', 'was', 'warum', 'how', 'what', 'why', 'where', 'when']):\n            semantic_score += 2\n        \n        # Long descriptive queries â†’ semantic search\n        if word_count > 8:\n            semantic_score += 1\n        \n        # Mixed signals or ambiguous â†’ hybrid\n        if keyword_score > 0 and semantic_score > 0:\n            return RetrievalStrategy.HYBRID\n        elif keyword_score > semantic_score:\n            return RetrievalStrategy.KEYWORD\n        elif semantic_score > 0:\n            return RetrievalStrategy.SEMANTIC\n        else:\n            return RetrievalStrategy.HYBRID  # Default to hybrid\n    \n    async def _semantic_only_search(\n        self, \n        query: str, \n        top_k: int, \n        filters: Optional[Dict[str, Any]]\n    ) -> List[HybridSearchResult]:\n        \"\"\"Pure vector-based semantic search\"\"\"\n        try:\n            # Generate query embedding\n            query_embedding = await self.embeddings.embed_query(query)\n            \n            # Search vector store\n            vector_results = await self.vectorstore.similarity_search(\n                query_embedding=query_embedding,\n                top_k=top_k,\n                filters=filters\n            )\n            \n            # Convert to hybrid results\n            results = []\n            for i, result in enumerate(vector_results):\n                hybrid_result = HybridSearchResult(\n                    chunk_id=result.get('id', f'chunk_{i}'),\n                    doc_id=result.get('doc_id', ''),\n                    content=result.get('text', result.get('content', '')),\n                    metadata=result.get('metadata', {}),\n                    final_score=result.get('similarity_score', 0.0),\n                    dense_score=result.get('similarity_score', 0.0),\n                    sparse_score=0.0,\n                    dense_rank=i + 1,\n                    sparse_rank=None,\n                    retrieval_source=\"semantic\"\n                )\n                results.append(hybrid_result)\n            \n            return results\n            \n        except Exception as e:\n            logger.error(f\"Semantic search failed: {str(e)}\")\n            return []\n    \n    async def _keyword_only_search(\n        self, \n        query: str, \n        top_k: int, \n        filters: Optional[Dict[str, Any]]\n    ) -> List[HybridSearchResult]:\n        \"\"\"Pure BM25 keyword search\"\"\"\n        try:\n            # Search with BM25\n            bm25_results = await self.bm25.search(\n                query=query,\n                top_k=top_k,\n                filters=filters,\n                min_score=0.1\n            )\n            \n            # Convert to hybrid results\n            results = []\n            for i, result in enumerate(bm25_results):\n                hybrid_result = HybridSearchResult(\n                    chunk_id=result.chunk_id,\n                    doc_id=result.doc_id,\n                    content=result.content,\n                    metadata=result.metadata,\n                    final_score=result.bm25_score,\n                    dense_score=0.0,\n                    sparse_score=result.bm25_score,\n                    dense_rank=None,\n                    sparse_rank=i + 1,\n                    matched_terms=result.matched_terms,\n                    retrieval_source=\"keyword\"\n                )\n                results.append(hybrid_result)\n            \n            return results\n            \n        except Exception as e:\n            logger.error(f\"Keyword search failed: {str(e)}\")\n            return []\n    \n    async def _hybrid_fusion_search(\n        self,\n        query: str,\n        top_k: int,\n        filters: Optional[Dict[str, Any]],\n        dense_top_k: int,\n        sparse_top_k: int\n    ) -> List[HybridSearchResult]:\n        \"\"\"Advanced hybrid search with Reciprocal Rank Fusion (RRF)\"\"\"\n        try:\n            # Execute both searches in parallel\n            dense_task = self._semantic_only_search(query, dense_top_k, filters)\n            sparse_task = self._keyword_only_search(query, sparse_top_k, filters)\n            \n            dense_results, sparse_results = await asyncio.gather(\n                dense_task, sparse_task, return_exceptions=True\n            )\n            \n            # Handle exceptions\n            if isinstance(dense_results, Exception):\n                logger.warning(f\"Dense retrieval failed: {str(dense_results)}\")\n                dense_results = []\n            if isinstance(sparse_results, Exception):\n                logger.warning(f\"Sparse retrieval failed: {str(sparse_results)}\")\n                sparse_results = []\n            \n            # Apply Reciprocal Rank Fusion (RRF)\n            fused_results = self._reciprocal_rank_fusion(\n                dense_results, sparse_results, top_k\n            )\n            \n            return fused_results\n            \n        except Exception as e:\n            logger.error(f\"Hybrid fusion search failed: {str(e)}\")\n            return []\n    \n    def _reciprocal_rank_fusion(\n        self,\n        dense_results: List[HybridSearchResult],\n        sparse_results: List[HybridSearchResult],\n        top_k: int,\n        k: int = 60  # RRF parameter\n    ) -> List[HybridSearchResult]:\n        \"\"\"\n        Combine results using Reciprocal Rank Fusion (RRF)\n        \n        RRF Formula: score(d) = Î£(1 / (k + rank(d)))\n        \n        Args:\n            dense_results: Vector search results\n            sparse_results: BM25 search results\n            top_k: Number of results to return\n            k: RRF parameter (typically 60)\n            \n        Returns:\n            Fused and ranked results\n        \"\"\"\n        # Build lookup maps\n        dense_map = {r.chunk_id: (i + 1, r) for i, r in enumerate(dense_results)}\n        sparse_map = {r.chunk_id: (i + 1, r) for i, r in enumerate(sparse_results)}\n        \n        # Collect all unique documents\n        all_chunk_ids = set(dense_map.keys()) | set(sparse_map.keys())\n        \n        fused_results = []\n        \n        for chunk_id in all_chunk_ids:\n            dense_rank, dense_result = dense_map.get(chunk_id, (None, None))\n            sparse_rank, sparse_result = sparse_map.get(chunk_id, (None, None))\n            \n            # Calculate RRF score\n            rrf_score = 0.0\n            \n            if dense_rank is not None:\n                rrf_score += self.dense_weight / (k + dense_rank)\n            \n            if sparse_rank is not None:\n                rrf_score += self.sparse_weight / (k + sparse_rank)\n            \n            # Use the result with more complete information\n            if dense_result and sparse_result:\n                # Merge information from both results\n                final_result = HybridSearchResult(\n                    chunk_id=chunk_id,\n                    doc_id=dense_result.doc_id or sparse_result.doc_id,\n                    content=dense_result.content or sparse_result.content,\n                    metadata={**dense_result.metadata, **sparse_result.metadata},\n                    final_score=rrf_score,\n                    dense_score=dense_result.dense_score,\n                    sparse_score=sparse_result.sparse_score,\n                    dense_rank=dense_rank,\n                    sparse_rank=sparse_rank,\n                    fusion_weight=self.dense_weight,\n                    matched_terms=sparse_result.matched_terms,\n                    retrieval_source=\"hybrid\"\n                )\n            elif dense_result:\n                final_result = dense_result\n                final_result.final_score = rrf_score\n                final_result.sparse_rank = None\n                final_result.sparse_score = 0.0\n            else:  # sparse_result\n                final_result = sparse_result\n                final_result.final_score = rrf_score\n                final_result.dense_rank = None\n                final_result.dense_score = 0.0\n            \n            fused_results.append(final_result)\n        \n        # Sort by RRF score and return top_k\n        fused_results.sort(key=lambda x: x.final_score, reverse=True)\n        \n        logger.debug(f\"RRF fusion: {len(dense_results)} dense + {len(sparse_results)} sparse â†’ {len(fused_results[:top_k])} results\")\n        \n        return fused_results[:top_k]\n    \n    def _update_performance_stats(self, response_time: float):\n        \"\"\"Update performance statistics\"\"\"\n        total_queries = self.query_stats['total_queries']\n        old_avg = self.query_stats['avg_response_time']\n        \n        # Update running average\n        self.query_stats['avg_response_time'] = (\n            (old_avg * (total_queries - 1) + response_time) / total_queries\n        )\n    \n    async def add_documents(self, documents: List[Dict[str, Any]]) -> None:\n        \"\"\"Add documents to both vector and BM25 indexes\"\"\"\n        try:\n            # Add to BM25 index\n            await self.bm25.add_documents(documents)\n            \n            # Documents should already be in vector store via normal pipeline\n            logger.info(f\"Added {len(documents)} documents to hybrid index\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to add documents to hybrid index: {str(e)}\")\n            raise\n    \n    async def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive retrieval statistics\"\"\"\n        bm25_stats = await self.bm25.get_index_stats()\n        \n        return {\n            'query_stats': self.query_stats,\n            'fusion_weights': {\n                'dense_weight': self.dense_weight,\n                'sparse_weight': self.sparse_weight\n            },\n            'bm25_stats': bm25_stats,\n            'vector_stats': {\n                'collection_name': getattr(self.vectorstore, 'collection_name', 'unknown'),\n                'initialized': hasattr(self.vectorstore, 'collection') and self.vectorstore.collection is not None\n            }\n        }\n    \n    def adjust_fusion_weights(self, dense_weight: float, sparse_weight: float):\n        \"\"\"Dynamically adjust fusion weights\"\"\"\n        self.dense_weight = dense_weight\n        self.sparse_weight = sparse_weight\n        self._normalize_weights()\n        \n        logger.info(f\"Fusion weights adjusted: dense={self.dense_weight:.2f}, sparse={self.sparse_weight:.2f}\")\n    \n    async def save_indexes(self):\n        \"\"\"Save all indexes to disk\"\"\"\n        await self.bm25.save_index()\n        logger.info(\"Hybrid retriever indexes saved\")