Testdokument für RAG Pipeline

Dies ist ein Testdokument für die Streamworks RAG Pipeline.

Das System verwendet lokale Gamma Embeddings für die Vektorisierung von Dokumenten und OpenAI oder Ollama für die Antwortgenerierung.

Key Features:
- Hybrid-Architektur mit lokalen Embeddings
- Zentrale Provider-Steuerung über LLM Factory
- Streaming-Support für Chat-Antworten
- JSON Mode für XML-Generierung
- Qdrant als Vector Database

Die RAG Pipeline funktioniert folgendermaßen:
1. Dokumente werden in Chunks aufgeteilt
2. Chunks werden mit Gamma Embeddings vektorisiert
3. Vektoren werden in Qdrant gespeichert
4. Bei Anfragen wird Semantic Search durchgeführt
5. Relevante Chunks werden als Kontext verwendet
6. LLM generiert Antwort basierend auf Kontext