# Core FastAPI & Server
fastapi[all]==0.116.0
uvicorn[standard]==0.32.1
python-multipart>=0.0.18
pydantic==2.10.3

# RAG Pipeline - LlamaIndex Ecosystem
llama-index>=0.11.0
llama-index-readers-file>=0.2.0
llama-index-embeddings-huggingface>=0.6.0
llama-index-vector-stores-qdrant>=0.2.0
llama-index-vector-stores-postgres>=0.2.0
llama-index-llms-ollama>=0.3.0
llama-index-postprocessor-flag-embedding-reranker>=0.2.0

# Embedding Models
transformers>=4.44.0
sentence-transformers>=2.7.0
torch>=2.4.0

# Vector Database
qdrant-client>=1.7.0
# Document Processing

# Text Processing & Utilities
numpy==1.26.4
lxml==5.3.0
unidecode==1.3.8

# LLM Providers - OpenAI & Ollama
openai>=1.35.0
ollama==0.4.4

# Image Processing
Pillow==10.4.0

# HTTP Client & Async
httpx>=0.27.0,<0.28.0
aiofiles==24.1.0

# Configuration & Environment
python-dotenv==1.0.1

# Database - PostgreSQL & Supabase
sqlalchemy[asyncio]==2.0.39
asyncpg==0.30.0
psycopg2-binary==2.9.9
supabase==2.11.0

# Development & Debugging
rich==13.9.4
loguru==0.7.2

# Smart Parameter Collection - MVP Dependencies
langchain>=0.1.0
langchain-core>=0.1.0
langchain-openai>=0.1.0
langchain-community>=0.1.0